{
    "task_id": "HumanEval/53",
    "prompt": "\n\ndef add(x: int, y: int):\n    \"\"\"Add two numbers x and y\n    >>> add(2, 3)\n    5\n    >>> add(5, 7)\n    12\n    \"\"\"\n",
    "canonical_solution": "    return x + y\n",
    "test": "\n\nMETADATA = {}\n\n\ndef check(candidate):\n    import random\n\n    assert candidate(0, 1) == 1\n    assert candidate(1, 0) == 1\n    assert candidate(2, 3) == 5\n    assert candidate(5, 7) == 12\n    assert candidate(7, 5) == 12\n\n    for i in range(100):\n        x, y = random.randint(0, 1000), random.randint(0, 1000)\n        assert candidate(x, y) == x + y\n\n",
    "entry_point": "add",
    "testbase": "\nMETADATA = {}\n\ndef check(candidate):\n    import random\n    assert (candidate(0, 1) == 1)\n",
    "coverage": 100.0,
    "coverage_testbase": 100.0,
    "num_iterations_used": 0,
    "msg_trace": {
        "1": {
            "generated_test_script": "\nMETADATA = {}\n\ndef check(candidate):\n    import random\n    assert (candidate(0, 1) == 1)\n",
            "coverage": 100.0,
            "exist_error": false,
            "executed_output": ""
        }
    },
    "best_score_generated_test_script": "\nMETADATA = {}\n\ndef check(candidate):\n    import random\n    assert (candidate(0, 1) == 1)\n",
    "first_generated_test_script": "\nMETADATA = {}\n\ndef check(candidate):\n    import random\n    assert (candidate(0, 1) == 1)\n",
    "not_error_best_generated_test_script": "\nMETADATA = {}\n\ndef check(candidate):\n    import random\n    assert (candidate(0, 1) == 1)\n",
    "filtered_generated_test_script": "\nMETADATA = {}\n\ndef check(candidate):\n    import random\n    assert (candidate(0, 1) == 1)\n",
    "exist_error": false,
    "best_score": 100.0,
    "first_score": 100.0,
    "not_error_best_score": 100.0,
    "exist_not_error": true,
    "filtered_score": 100.0,
    "use_filter": false
}