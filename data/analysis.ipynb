{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Agent without Tesbase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gpt35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Coverage Score : 98.7683%\n",
      "Rate of correct test script: 76.2195% with 125 correct per 164\n",
      "Golden Coverage Score: 99.4390243902439\n",
      "List of samples less than desired coverage [59, 99, 124, 127, 140]\n",
      "List of samples raise graph error [] 0\n"
     ]
    }
   ],
   "source": [
    "avg_final_coverage = 0\n",
    "not_error_avg_final_coverage = 0\n",
    "golden_avg_coverage = 0\n",
    "correct_count = 0\n",
    "total = 0\n",
    "error = []\n",
    "unreachable = []\n",
    "\n",
    "for i in range(164): \n",
    "    try:\n",
    "        with open(os.getcwd() + f'/HumanEvalCoverageMultiAgent_gpt35_gpt35/{i}.json', 'r') as f:\n",
    "            data = json.load(f)\n",
    "            if data[\"best_score\"] < 100:\n",
    "                unreachable.append(i)\n",
    "                \n",
    "            # ASSUMPTION\n",
    "            if data.get(\"exception\", None):\n",
    "                error.append(i)\n",
    "\n",
    "            # NORMAL CASE\n",
    "            if data[\"exist_not_error\"]:\n",
    "                avg_final_coverage += data[\"not_error_best_score\"] \n",
    "                correct_count += 1\n",
    "            else:\n",
    "                avg_final_coverage += data[\"best_score\"] # get final best one\n",
    "                correct_count += 0\n",
    "\n",
    "            golden_avg_coverage += data['coverage']\n",
    "            total += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e, i)\n",
    "        break\n",
    "\n",
    "print(f\"Average Coverage Score : {avg_final_coverage/total:.4f}%\")\n",
    "print(f\"Rate of correct test script: {correct_count/total*100:.4f}% with {correct_count} correct per {total}\")\n",
    "print(\"Golden Coverage Score:\", golden_avg_coverage/total)\n",
    "print(\"List of samples less than desired coverage\", unreachable)\n",
    "print(\"List of samples raise graph error\", error, len(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gpt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Coverage Score : 99.9085%\n",
      "Rate of correct test script: 77.4390% with 127 correct per 164\n",
      "Golden Coverage Score: 99.4390243902439\n",
      "List of samples less than desired coverage [59, 99]\n",
      "List of samples raise graph error [] 0\n"
     ]
    }
   ],
   "source": [
    "avg_final_coverage = 0\n",
    "not_error_avg_final_coverage = 0\n",
    "golden_avg_coverage = 0\n",
    "correct_count = 0\n",
    "total = 0\n",
    "error = []\n",
    "unreachable = []\n",
    "\n",
    "for i in range(164): \n",
    "    try:\n",
    "        with open(os.getcwd() + f'/HumanEvalCoverageMultiAgent_gpt4_gpt4/{i}.json', 'r') as f:\n",
    "            data = json.load(f)\n",
    "            if data[\"best_score\"] < 100:\n",
    "                unreachable.append(i)\n",
    "\n",
    "            # ASSUMPTION\n",
    "            if data.get(\"exception\", None):\n",
    "                error.append(i)\n",
    "                               \n",
    "            # NORMAL CASE\n",
    "            if data[\"exist_not_error\"]:\n",
    "                avg_final_coverage += data[\"not_error_best_score\"] \n",
    "                correct_count += 1\n",
    "            else:\n",
    "                avg_final_coverage += data[\"best_score\"] # get final best one\n",
    "                correct_count += 0\n",
    "                if data[\"best_score\"] < 100:\n",
    "                    lss.append(i)\n",
    "                \n",
    "            golden_avg_coverage += data['coverage']\n",
    "            total += 1\n",
    "\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break\n",
    "    \n",
    "print(f\"Average Coverage Score : {avg_final_coverage/total:.4f}%\")\n",
    "print(f\"Rate of correct test script: {correct_count/total*100:.4f}% with {correct_count} correct per {total}\")\n",
    "print(\"Golden Coverage Score:\", golden_avg_coverage/total)\n",
    "print(\"List of samples less than desired coverage\", unreachable)\n",
    "print(\"List of samples raise graph error\", error, len(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Coverage Score : 94.2500%\n",
      "Rate of correct test script: 76.8293% with 126 correct per 164\n",
      "Golden Coverage Score: 99.4390243902439\n",
      "List of samples less than desired coverage [59, 99, 152]\n",
      "List of samples raise graph error []\n"
     ]
    }
   ],
   "source": [
    "avg_final_coverage = 0\n",
    "golden_avg_coverage = 0\n",
    "correct_count = 0\n",
    "total = 0\n",
    "error = []\n",
    "unreachable = []\n",
    "\n",
    "for i in range(164): \n",
    "    try:\n",
    "        with open(os.getcwd() + f'/HumanEvalCoverageMultiAgent_claude_claude/{i}.json', 'r') as f:\n",
    "            data = json.load(f)\n",
    "            if data[\"best_score\"] < 100:\n",
    "                unreachable.append(i)\n",
    "\n",
    "            # ASSUMPTION\n",
    "            if data.get(\"exception\", None):\n",
    "                error.append(i)\n",
    "                \n",
    "            # NORMAL CASE\n",
    "            if data[\"exist_not_error\"]:\n",
    "                avg_final_coverage += data[\"not_error_best_score\"] \n",
    "                correct_count += 1\n",
    "            else:\n",
    "                avg_final_coverage += data[\"best_score\"] # get final best one\n",
    "                correct_count += 0\n",
    "                \n",
    "            golden_avg_coverage += data['coverage']\n",
    "            total += 1\n",
    "\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break\n",
    "\n",
    "print(f\"Average Coverage Score : {avg_final_coverage/total:.4f}%\")\n",
    "print(f\"Rate of correct test script: {correct_count/total*100:.4f}% with {correct_count} correct per {total}\")\n",
    "print(\"Golden Coverage Score:\", golden_avg_coverage/total)\n",
    "print(\"List of samples less than desired coverage\", unreachable)\n",
    "print(\"List of samples raise graph error\", error) # 133"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## codeqwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Coverage Score : 97.4756%\n",
      "Rate of correct test script: 75.6098% with 124 correct per 164\n",
      "Golden Coverage Score: 99.4390243902439\n",
      "List of samples less than desired coverage [4, 32, 59, 65, 82, 99, 102, 123, 127]\n",
      "List of samples raise graph error []\n"
     ]
    }
   ],
   "source": [
    "avg_final_coverage = 0\n",
    "golden_avg_coverage = 0\n",
    "correct_count = 0\n",
    "total = 0\n",
    "error = []\n",
    "unreachable = []\n",
    "less_desired = []\n",
    "error_lst = []\n",
    "for i in range(164): \n",
    "    try:\n",
    "        with open(os.getcwd() + f'/HumanEvalCoverageMultiAgent_codeqwen_codeqwen/{i}.json', 'r') as f:\n",
    "            data = json.load(f)\n",
    "            if data[\"best_score\"] < 100:\n",
    "                unreachable.append(i)\n",
    "\n",
    "            # ASSUMPTION\n",
    "            if data.get(\"exception\", None):\n",
    "                error.append(i)\n",
    "\n",
    "            # NORMAL CASE\n",
    "            if data[\"exist_not_error\"]:\n",
    "                avg_final_coverage += data[\"not_error_best_score\"] \n",
    "                correct_count += 1\n",
    "            else:\n",
    "                avg_final_coverage += data[\"best_score\"] # get final best one\n",
    "                correct_count += 0\n",
    "            \n",
    "                \n",
    "            golden_avg_coverage += data['coverage']\n",
    "            total += 1\n",
    "\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break\n",
    "\n",
    "print(f\"Average Coverage Score : {avg_final_coverage/total:.4f}%\")\n",
    "print(f\"Rate of correct test script: {correct_count/total*100:.4f}% with {correct_count} correct per {total}\")\n",
    "print(\"Golden Coverage Score:\", golden_avg_coverage/total)\n",
    "print(\"List of samples less than desired coverage\", unreachable)\n",
    "print(\"List of samples raise graph error\", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## deepseek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Coverage Score : 91.8476%\n",
      "Rate of correct test script: 53.0488% with 87 correct per 164\n",
      "Golden Coverage Score: 99.4390243902439\n",
      "List of samples less than desired coverage [44, 59, 63, 99, 123, 141]\n",
      "List of samples raise graph error []\n"
     ]
    }
   ],
   "source": [
    "avg_final_coverage = 0\n",
    "golden_avg_coverage = 0\n",
    "correct_count = 0\n",
    "total = 0\n",
    "error = []\n",
    "unreachable = []\n",
    "lss = []\n",
    "for i in range(164): \n",
    "    try:\n",
    "        with open(os.getcwd() + f'/HumanEvalCoverageMultiAgent_deepseek_deepseek/{i}.json', 'r') as f:\n",
    "            data = json.load(f)\n",
    "            if data[\"best_score\"] < 100:\n",
    "                unreachable.append(i)\n",
    "                \n",
    "            # ASSUMPTION\n",
    "            if data.get(\"exception\", None):\n",
    "                error.append(i)\n",
    "\n",
    "            # NORMAL CASE\n",
    "            if data[\"exist_not_error\"]:\n",
    "                avg_final_coverage += data[\"not_error_best_score\"] \n",
    "                correct_count += 1\n",
    "            else:\n",
    "                avg_final_coverage += data[\"best_score\"] # get final best one\n",
    "                correct_count += 0\n",
    "                \n",
    "            golden_avg_coverage += data['coverage']\n",
    "            total += 1\n",
    "\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break\n",
    "\n",
    "print(f\"Average Coverage Score : {avg_final_coverage/total:.4f}%\")\n",
    "print(f\"Rate of correct test script: {correct_count/total*100:.4f}% with {correct_count} correct per {total}\")\n",
    "print(\"Golden Coverage Score:\", golden_avg_coverage/total)\n",
    "print(\"List of samples less than desired coverage\", unreachable)\n",
    "print(\"List of samples raise graph error\", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Agent without Testbase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gpt35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Coverage Score : 77.8963%\n",
      "Rate of correct test script: 65.8537% with 108 correct per 164\n",
      "Golden Coverage Score: 99.4390243902439\n",
      "List of samples less than desired coverage [0, 3, 11, 13, 16, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32, 33, 34, 35, 37, 39, 41, 42, 43, 47, 52, 53, 57, 58, 59, 60, 62, 75, 79, 81, 84, 85, 87, 99, 102, 105, 106, 108, 112, 113, 115, 120, 122, 127, 128, 129, 135, 140, 142, 143, 152, 155, 160]\n",
      "List of samples raise graph error []\n"
     ]
    }
   ],
   "source": [
    "avg_final_coverage = 0\n",
    "golden_avg_coverage = 0\n",
    "correct_count = 0\n",
    "total = 0\n",
    "error = []\n",
    "unreachable = []\n",
    "for i in range(164): \n",
    "    try:\n",
    "        with open(os.getcwd() + f'/HumanEvalCoverageSingle_gpt35/{i}.json', 'r') as f:\n",
    "            data = json.load(f)\n",
    "            if data[\"best_score\"] < 100:\n",
    "                unreachable.append(i)\n",
    "                \n",
    "            # ASSUMPTION\n",
    "            if data.get(\"exception\", None):\n",
    "                error.append(i)\n",
    "\n",
    "            # NORMAL CASE\n",
    "            if data['msg_trace'] == {}:\n",
    "                print(i)\n",
    "            if data[\"exist_not_error\"]:\n",
    "                avg_final_coverage += data[\"not_error_best_score\"] \n",
    "                correct_count += 1\n",
    "            else:\n",
    "                avg_final_coverage += data[\"best_score\"] # get final best one\n",
    "                correct_count += 0\n",
    "                \n",
    "            golden_avg_coverage += data['coverage']\n",
    "            total += 1\n",
    "\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Average Coverage Score : {avg_final_coverage/total:.4f}%\")\n",
    "print(f\"Rate of correct test script: {correct_count/total*100:.4f}% with {correct_count} correct per {total}\")\n",
    "print(\"Golden Coverage Score:\", golden_avg_coverage/total)\n",
    "print(\"List of samples less than desired coverage\", unreachable)\n",
    "print(\"List of samples raise graph error\", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gpt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Coverage Score : 81.3476%\n",
      "Rate of correct test script: 69.5122% with 114 correct per 164\n",
      "Golden Coverage Score: 99.4390243902439\n",
      "List of samples less than desired coverage [59, 76, 99, 103, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 116, 117, 118, 122, 126, 128, 132, 133, 135, 136, 140, 143, 145, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 159, 160, 161, 163]\n",
      "List of samples raise graph error []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "avg_final_coverage = 0\n",
    "golden_avg_coverage = 0\n",
    "correct_count = 0\n",
    "total = 0\n",
    "error = []\n",
    "unreachable = []\n",
    "for i in range(164): \n",
    "    try:\n",
    "        with open(os.getcwd() + f'/HumanEvalCoverageSingle_gpt4/{i}.json', 'r') as f:\n",
    "            data = json.load(f)\n",
    "            if data[\"best_score\"] < 100:\n",
    "                unreachable.append(i)\n",
    "                \n",
    "            # ASSUMPTION\n",
    "            if data.get(\"exception\", None):\n",
    "                error.append(i)\n",
    "\n",
    "            # NORMAL CASE\n",
    "            if data[\"exist_not_error\"]:\n",
    "                avg_final_coverage += data[\"not_error_best_score\"] \n",
    "                correct_count += 1\n",
    "            else:\n",
    "                avg_final_coverage += data[\"best_score\"] # get final best one\n",
    "                correct_count += 0\n",
    "                \n",
    "            golden_avg_coverage += data['coverage']\n",
    "            total += 1\n",
    "\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break\n",
    "\n",
    "\n",
    "print(f\"Average Coverage Score : {avg_final_coverage/total:.4f}%\")\n",
    "print(f\"Rate of correct test script: {correct_count/total*100:.4f}% with {correct_count} correct per {total}\")\n",
    "print(\"Golden Coverage Score:\", golden_avg_coverage/total)\n",
    "print(\"List of samples less than desired coverage\", unreachable)\n",
    "print(\"List of samples raise graph error\", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Coverage Score : 72.4573%\n",
      "Rate of correct test script: 73.7805% with 121 correct per 164\n",
      "Golden Coverage Score: 99.4390243902439\n",
      "List of samples less than desired coverage [1, 20, 22, 31, 32, 33, 35, 36, 39, 40, 50, 59, 60, 61, 63, 68, 71, 75, 77, 81, 82, 84, 86, 87, 89, 91, 96, 99, 103, 104, 105, 107, 108, 109, 110, 116, 117, 118, 119, 124, 126, 127, 131, 135, 137, 140, 141, 142, 143, 146, 149, 152, 156, 158, 160, 161, 162]\n",
      "List of samples raise graph error []\n"
     ]
    }
   ],
   "source": [
    "avg_final_coverage = 0\n",
    "golden_avg_coverage = 0\n",
    "correct_count = 0\n",
    "total = 0\n",
    "error = []\n",
    "unreachable = []\n",
    "for i in range(164): \n",
    "    try:\n",
    "        with open(os.getcwd() + f'/HumanEvalCoverageSingle_claude/{i}.json', 'r') as f:\n",
    "            data = json.load(f)\n",
    "            if data[\"best_score\"] < 100:\n",
    "                unreachable.append(i)\n",
    "                \n",
    "            # ASSUMPTION\n",
    "            if data.get(\"exception\", None):\n",
    "                error.append(i)\n",
    "\n",
    "            # NORMAL CASE\n",
    "            if data[\"exist_not_error\"]:\n",
    "                avg_final_coverage += data[\"not_error_best_score\"] \n",
    "                correct_count += 1\n",
    "            else:\n",
    "                avg_final_coverage += data[\"best_score\"] # get final best one\n",
    "                correct_count += 0\n",
    "                \n",
    "            golden_avg_coverage += data['coverage']\n",
    "            total += 1\n",
    "\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break\n",
    "\n",
    "print(f\"Average Coverage Score : {avg_final_coverage/total:.4f}%\")\n",
    "print(f\"Rate of correct test script: {correct_count/total*100:.4f}% with {correct_count} correct per {total}\")\n",
    "print(\"Golden Coverage Score:\", golden_avg_coverage/total)\n",
    "print(\"List of samples less than desired coverage\", unreachable)\n",
    "print(\"List of samples raise graph error\", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## codeqwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Coverage Score : 95.4878%\n",
      "Rate of correct test script: 68.9024% with 113 correct per 164\n",
      "Golden Coverage Score: 99.4390243902439\n",
      "List of samples less than desired coverage [32, 43, 46, 59, 65, 72, 75, 81, 95, 99, 100, 124, 127, 131, 138, 140, 141, 148, 149, 150, 151, 153, 154]\n",
      "List of samples raise graph error []\n"
     ]
    }
   ],
   "source": [
    "avg_final_coverage = 0\n",
    "golden_avg_coverage = 0\n",
    "correct_count = 0\n",
    "total = 0\n",
    "error = []\n",
    "unreachable = []\n",
    "for i in range(164): \n",
    "    try:\n",
    "        with open(os.getcwd() + f'/HumanEvalCoverageSingle_codeqwen/{i}.json', 'r') as f:\n",
    "            data = json.load(f)\n",
    "            if data[\"best_score\"] < 100:\n",
    "                unreachable.append(i)\n",
    "                \n",
    "            # ASSUMPTION\n",
    "            if data.get(\"exception\", None):\n",
    "                error.append(i)\n",
    "\n",
    "            # NORMAL CASE\n",
    "            if data['msg_trace'] == {}:\n",
    "                print(i)\n",
    "            if data[\"exist_not_error\"]:\n",
    "                avg_final_coverage += data[\"not_error_best_score\"] \n",
    "                correct_count += 1\n",
    "            else:\n",
    "                avg_final_coverage += data[\"best_score\"] # get final best one\n",
    "                correct_count += 0\n",
    "                \n",
    "            golden_avg_coverage += data['coverage']\n",
    "            total += 1\n",
    "\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break\n",
    "\n",
    "\n",
    "print(f\"Average Coverage Score : {avg_final_coverage/total:.4f}%\")\n",
    "print(f\"Rate of correct test script: {correct_count/total*100:.4f}% with {correct_count} correct per {total}\")\n",
    "print(\"Golden Coverage Score:\", golden_avg_coverage/total)\n",
    "print(\"List of samples less than desired coverage\", unreachable)\n",
    "print(\"List of samples raise graph error\", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Coverage Score : 95.4878%\n",
      "Rate of correct test script: 68.9024% with 113 correct per 164\n",
      "Golden Coverage Score: 99.4390243902439\n",
      "List of samples less than desired coverage [32, 43, 46, 59, 65, 72, 75, 81, 95, 99, 100, 124, 127, 131, 138, 140, 141, 148, 149, 150, 151, 153, 154]\n",
      "List of samples raise graph error [] 0\n"
     ]
    }
   ],
   "source": [
    "avg_final_coverage = 0\n",
    "not_error_avg_final_coverage = 0\n",
    "golden_avg_coverage = 0\n",
    "correct_count = 0\n",
    "total = 0\n",
    "error = []\n",
    "unreachable = []\n",
    "\n",
    "for i in range(164): \n",
    "    try:\n",
    "        with open(os.getcwd() + f'/HumanEvalCoverageSingle_codeqwen/{i}.json', 'r') as f:\n",
    "            data = json.load(f)\n",
    "            if data[\"best_score\"] < 100:\n",
    "                unreachable.append(i)\n",
    "                \n",
    "            # ASSUMPTION\n",
    "            if data.get(\"exception\", None):\n",
    "                error.append(i)\n",
    "\n",
    "            # NORMAL CASE\n",
    "            if data[\"exist_not_error\"]:\n",
    "                avg_final_coverage += data[\"not_error_best_score\"] \n",
    "                correct_count += 1\n",
    "            else:\n",
    "                avg_final_coverage += data[\"best_score\"] # get final best one\n",
    "                correct_count += 0\n",
    "            \n",
    "            golden_avg_coverage += data['coverage']\n",
    "            total += 1\n",
    "\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(e, i)\n",
    "        break\n",
    "\n",
    "print(f\"Average Coverage Score : {avg_final_coverage/total:.4f}%\")\n",
    "print(f\"Rate of correct test script: {correct_count/total*100:.4f}% with {correct_count} correct per {total}\")\n",
    "print(\"Golden Coverage Score:\", golden_avg_coverage/total)\n",
    "print(\"List of samples less than desired coverage\", unreachable)\n",
    "print(\"List of samples raise graph error\", error, len(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## deepseek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Coverage Score : 90.4207%\n",
      "Rate of correct test script: 42.0732% with 69 correct per 164\n",
      "Golden Coverage Score: 99.4390243902439\n",
      "List of samples less than desired coverage [24, 27, 32, 44, 46, 57, 59, 63, 64, 65, 73, 76, 81, 89, 99, 113, 118, 119, 121, 123, 124, 127, 130, 140, 141, 147, 154, 155]\n",
      "List of samples raise graph error []\n"
     ]
    }
   ],
   "source": [
    "avg_final_coverage = 0\n",
    "golden_avg_coverage = 0\n",
    "correct_count = 0\n",
    "total = 0\n",
    "error = []\n",
    "unreachable = []\n",
    "for i in range(164): \n",
    "    try:\n",
    "        with open(os.getcwd() + f'/HumanEvalCoverageSingle_deepseek/{i}.json', 'r') as f:\n",
    "            data = json.load(f)\n",
    "            if data[\"best_score\"] < 100:\n",
    "                unreachable.append(i)\n",
    "                \n",
    "            # ASSUMPTION\n",
    "            if data.get(\"exception\", None):\n",
    "                error.append(i)\n",
    "\n",
    "            # NORMAL CASE\n",
    "            if data[\"exist_not_error\"]:\n",
    "                avg_final_coverage += data[\"not_error_best_score\"] \n",
    "                correct_count += 1\n",
    "            else:\n",
    "                avg_final_coverage += data[\"best_score\"] # get final best one\n",
    "                correct_count += 0\n",
    "                \n",
    "            golden_avg_coverage += data['coverage']\n",
    "            total += 1\n",
    "\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break\n",
    "\n",
    "\n",
    "print(f\"Average Coverage Score : {avg_final_coverage/total:.4f}%\")\n",
    "print(f\"Rate of correct test script: {correct_count/total*100:.4f}% with {correct_count} correct per {total}\")\n",
    "print(\"Golden Coverage Score:\", golden_avg_coverage/total)\n",
    "print(\"List of samples less than desired coverage\", unreachable)\n",
    "print(\"List of samples raise graph error\", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Agent WITH testbase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gpt35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Average Coverage Score : 97.6829%\n",
      "Rate of correct test script: 90.8537% with 149 correct per 164\n",
      "Golden Coverage Score: 99.4390243902439\n",
      "Golden Testbase Coverage Score: 65.29878048780488\n",
      "List of samples less than desired coverage [59, 81, 99, 119, 124, 127, 153]\n",
      "List of samples raise graph error []\n"
     ]
    }
   ],
   "source": [
    "avg_final_coverage = 0\n",
    "golden_avg_coverage = 0\n",
    "correct_count = 0\n",
    "total = 0\n",
    "error = []\n",
    "unreachable = []\n",
    "lss = []\n",
    "golden_testbase = 0\n",
    "for i in range(164): \n",
    "    try:\n",
    "        with open(os.getcwd() + f'/HumanEvalCoverageMultiAgent_gpt35_gpt35_testbase/{i}.json', 'r') as f:\n",
    "            data = json.load(f)\n",
    "            if data[\"best_score\"] < 100:\n",
    "                unreachable.append(i)\n",
    "                \n",
    "            # ASSUMPTION\n",
    "            if data.get(\"exception\", None):\n",
    "                error.append(i)\n",
    "\n",
    "            # NORMAL CASE\n",
    "            if data['msg_trace'] == {}:\n",
    "                print(i)\n",
    "                \n",
    "            if data[\"exist_not_error\"]:\n",
    "                avg_final_coverage += data[\"not_error_best_score\"] \n",
    "                correct_count += 1\n",
    "\n",
    "            else:\n",
    "                avg_final_coverage += data[\"best_score\"] # get final best one\n",
    "                correct_count += 0\n",
    "\n",
    "            golden_testbase += data[\"coverage_testbase\"]\n",
    "            golden_avg_coverage += data['coverage']\n",
    "            total += 1\n",
    "\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break\n",
    "            \n",
    "print(lss)\n",
    "\n",
    "print(f\"Average Coverage Score : {avg_final_coverage/total:.4f}%\")\n",
    "print(f\"Rate of correct test script: {correct_count/total*100:.4f}% with {correct_count} correct per {total}\")\n",
    "print(\"Golden Coverage Score:\", golden_avg_coverage/total)\n",
    "print(\"Golden Testbase Coverage Score:\", golden_testbase/total)\n",
    "print(\"List of samples less than desired coverage\", unreachable)\n",
    "print(\"List of samples raise graph error\", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gpt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Coverage Score : 98.1159%\n",
      "Rate of correct test script: 93.9024% with 154 correct per 164\n",
      "Golden Coverage Score: 99.4390243902439\n",
      "Golden Testbase Coverage Score: 77.6219512195122\n",
      "List of samples less than desired coverage [59, 99]\n",
      "List of samples raise graph error []\n"
     ]
    }
   ],
   "source": [
    "avg_final_coverage = 0\n",
    "golden_avg_coverage = 0\n",
    "correct_count = 0\n",
    "total = 0\n",
    "error = []\n",
    "unreachable = []\n",
    "golden_testbase = 0\n",
    "for i in range(164): \n",
    "    try:\n",
    "        with open(os.getcwd() + f'/HumanEvalCoverageMultiAgent_gpt4_gpt4_testbase/{i}.json', 'r') as f:\n",
    "            data = json.load(f)\n",
    "            if data[\"best_score\"] < 100:\n",
    "                unreachable.append(i)\n",
    "                \n",
    "            # ASSUMPTION\n",
    "            if data.get(\"exception\", None):\n",
    "                error.append(i)\n",
    "\n",
    "            # NORMAL CASE\n",
    "            if data[\"exist_not_error\"]:\n",
    "                avg_final_coverage += data[\"not_error_best_score\"] \n",
    "                correct_count += 1\n",
    "            else:\n",
    "                avg_final_coverage += data[\"best_score\"] # get final best one\n",
    "                correct_count += 0\n",
    "\n",
    "            golden_testbase += data[\"coverage_testbase\"]\n",
    "            golden_avg_coverage += data['coverage']\n",
    "            total += 1\n",
    "\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break\n",
    "\n",
    "\n",
    "print(f\"Average Coverage Score : {avg_final_coverage/total:.4f}%\")\n",
    "print(f\"Rate of correct test script: {correct_count/total*100:.4f}% with {correct_count} correct per {total}\")\n",
    "print(\"Golden Coverage Score:\", golden_avg_coverage/total)\n",
    "print(\"Golden Testbase Coverage Score:\", golden_testbase/total)\n",
    "print(\"List of samples less than desired coverage\", unreachable)\n",
    "print(\"List of samples raise graph error\", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Coverage Score : 98.3171%\n",
      "Rate of correct test script: 84.1463% with 138 correct per 164\n",
      "Golden Coverage Score: 99.4390243902439\n",
      "List of samples less than desired coverage [59, 99]\n",
      "List of samples raise graph error []\n"
     ]
    }
   ],
   "source": [
    "avg_final_coverage = 0\n",
    "golden_avg_coverage = 0\n",
    "correct_count = 0\n",
    "total = 0\n",
    "error = []\n",
    "unreachable = []\n",
    "lss = []\n",
    "for i in range(164): \n",
    "    try:\n",
    "        with open(os.getcwd() + f'/HumanEvalCoverageMultiAgent_claude_claude_testbase/{i}.json', 'r') as f:\n",
    "            data = json.load(f)\n",
    "            if data[\"best_score\"] < 100:\n",
    "                unreachable.append(i)\n",
    "                \n",
    "            # ASSUMPTION\n",
    "            if data.get(\"exception\", None):\n",
    "                error.append(i)\n",
    "\n",
    "            # NORMAL CASE\n",
    "            if data[\"exist_not_error\"]:\n",
    "                avg_final_coverage += data[\"not_error_best_score\"] \n",
    "                correct_count += 1\n",
    "\n",
    "            else:\n",
    "                avg_final_coverage += data[\"best_score\"] # get final best one\n",
    "                correct_count += 0\n",
    "\n",
    "            golden_avg_coverage += data['coverage']\n",
    "            total += 1\n",
    "\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break\n",
    "\n",
    "print(f\"Average Coverage Score : {avg_final_coverage/total:.4f}%\")\n",
    "print(f\"Rate of correct test script: {correct_count/total*100:.4f}% with {correct_count} correct per {total}\")\n",
    "print(\"Golden Coverage Score:\", golden_avg_coverage/total)\n",
    "print(\"List of samples less than desired coverage\", unreachable)\n",
    "print(\"List of samples raise graph error\", error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "api_mapping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
